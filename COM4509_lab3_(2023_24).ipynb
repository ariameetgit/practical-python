{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariameetgit/practical-python/blob/main/COM4509_lab3_(2023_24).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16VKs4sE14HS"
      },
      "source": [
        "# Decision trees and ensemble methods\n",
        "\n",
        "A [decision tree](https://en.wikipedia.org/wiki/Decision_tree_learning) can be thought of as a sequence of **hierarchical if-else statements** that test feature values to predict a class.\n",
        "\n",
        "\n",
        "In this notebook we will explore the use of [scikit-learn](https://scikit-learn.org/stable/) for Decision Trees. This first example will allow us to understand some of the parameters in a decision tree.\n",
        "\n",
        "\n",
        "## Decision trees with scikit-learn\n",
        "\n",
        "We will build a classifier that will be able to detect spam from the text in an email. We'll use the  [Spambase Dataset](http://archive.ics.uci.edu/ml/datasets/Spambase) from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php).\n",
        "\n",
        "The dataset contains 57 features related to word frequency, character frequency, and others related to capital letters. The description of the features and labels in the dataset is available [here](http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names). The output label indicates whether an email was considered 'ham' or 'spam', so it is a binary label (1=spam).\n",
        "\n",
        "We will use Decision trees as our predictive model. But first, we need to get the data and the names of the attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kyPs6NLO14Hb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "spam_data = pd.read_csv('https://docs.google.com/uc?export=download&id=1nQVmHSzBLhMschMsAO4aZMhIgfW7qu-_', header=None)\n",
        "spam_names_list = pd.read_csv('https://docs.google.com/uc?export=download&id=1GgLZoUqyVGO21h5Iso30tOXwNBloVU4T', header=None, delimiter=\":\")\n",
        "spam_names = spam_names_list[0]\n",
        "spam_data.columns = spam_names\n",
        "X = spam_data.iloc[:, 0:57]\n",
        "y = spam_data.iloc[:, 57]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLbjAZq-14He"
      },
      "outputs": [],
      "source": [
        "spam_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d6RIud214Hi"
      },
      "source": [
        "### Visualising decision trees\n",
        "\n",
        "To demonstrate the classifier, we keep things simple for now and use the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0JAXTca314Hk"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "clf = clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVDKUMSe14Hs",
        "outputId": "50f4ea06-90f8-471c-97fa-e452c8242a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxEHS4Wm14Hv"
      },
      "source": [
        "From lectures you'll remember that `criterion='entropy'` means that we are looking to maximise information gain. Having a `max_depth=3` can help reduce overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lJ2LaUk14Hx"
      },
      "source": [
        "To visualize the tree, we can use the [Graphviz](http://www.graphviz.org/) package and use the exporter [export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz). It is installed by default on colab. If you need to install the package use (on the commandline):\n",
        "\n",
        "`conda install python-graphviz`\n",
        "\n",
        "or, if there are errors, you could try with `pip` instead:\n",
        "\n",
        "`pip install graphviz`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cvZk9hCt14H8"
      },
      "outputs": [],
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf, out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "#If you want to export the tree as a pdf file, use:\n",
        "#graph.render(\"spam\")\n",
        "#If you're using colab, you need to click on the \"Files\" button on the left-hand toolbar. You'll then be able to see `spam.pdf`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can draw the graph with:"
      ],
      "metadata": {
        "id": "lEloxlz86AJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph"
      ],
      "metadata": {
        "id": "whN3gW-m7AGs",
        "outputId": "436c20db-f71f-4977-899e-0c6a7f329eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1039pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 1039.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-369 1035,-369 1035,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"604,-365 464,-365 464,-297 604,-297 604,-365\"/>\n<text text-anchor=\"middle\" x=\"534\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[52] &lt;= 0.056</text>\n<text text-anchor=\"middle\" x=\"534\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.967</text>\n<text text-anchor=\"middle\" x=\"534\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4601</text>\n<text text-anchor=\"middle\" x=\"534\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2788, 1813]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"474,-261 342,-261 342,-193 474,-193 474,-261\"/>\n<text text-anchor=\"middle\" x=\"408\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[6] &lt;= 0.055</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.787</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3471</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2655, 816]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M493.09,-296.88C481.65,-287.62 469.09,-277.45 457.22,-267.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"459.11,-264.87 449.13,-261.3 454.7,-270.31 459.11,-264.87\"/>\n<text text-anchor=\"middle\" x=\"451.75\" y=\"-282.46\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"730.5,-261 605.5,-261 605.5,-193 730.5,-193 730.5,-261\"/>\n<text text-anchor=\"middle\" x=\"668\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[24] &lt;= 0.4</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.523</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1130</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [133, 997]</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M577.51,-296.88C589.79,-287.53 603.29,-277.26 616.02,-267.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"618.42,-270.14 624.25,-261.3 614.18,-264.57 618.42,-270.14\"/>\n<text text-anchor=\"middle\" x=\"620.89\" y=\"-282.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"279,-157 147,-157 147,-89 279,-89 279,-157\"/>\n<text text-anchor=\"middle\" x=\"213\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[51] &lt;= 0.191</text>\n<text text-anchor=\"middle\" x=\"213\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.644</text>\n<text text-anchor=\"middle\" x=\"213\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3141</text>\n<text text-anchor=\"middle\" x=\"213\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2625, 516]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M344.69,-192.88C325.78,-182.99 304.9,-172.07 285.45,-161.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"286.81,-158.66 276.33,-157.12 283.57,-164.86 286.81,-158.66\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"466.5,-157 349.5,-157 349.5,-89 466.5,-89 466.5,-157\"/>\n<text text-anchor=\"middle\" x=\"408\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[26] &lt;= 0.14</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.439</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 330</text>\n<text text-anchor=\"middle\" x=\"408\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 300]</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M408,-192.88C408,-184.78 408,-175.98 408,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"411.5,-167.3 408,-157.3 404.5,-167.3 411.5,-167.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"132,-53 0,-53 0,0 132,0 132,-53\"/>\n<text text-anchor=\"middle\" x=\"66\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.412</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2524</text>\n<text text-anchor=\"middle\" x=\"66\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2315, 209]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M161.59,-88.95C146.36,-79.16 129.74,-68.48 114.69,-58.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"116.34,-55.7 106.03,-53.24 112.55,-61.59 116.34,-55.7\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"275.5,-53 150.5,-53 150.5,0 275.5,0 275.5,-53\"/>\n<text text-anchor=\"middle\" x=\"213\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"213\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 617</text>\n<text text-anchor=\"middle\" x=\"213\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [310, 307]</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M213,-88.95C213,-80.72 213,-71.85 213,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.5,-63.24 213,-53.24 209.5,-63.24 216.5,-63.24\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"410.5,-53 293.5,-53 293.5,0 410.5,0 410.5,-53\"/>\n<text text-anchor=\"middle\" x=\"352\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.302</text>\n<text text-anchor=\"middle\" x=\"352\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 317</text>\n<text text-anchor=\"middle\" x=\"352\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 300]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M388.41,-88.95C383.26,-80.26 377.7,-70.86 372.5,-62.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"375.36,-60.06 367.25,-53.24 369.34,-63.62 375.36,-60.06\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"531,-53 429,-53 429,0 531,0 531,-53\"/>\n<text text-anchor=\"middle\" x=\"480\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"480\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"middle\" x=\"480\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 0]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M433.18,-88.95C440.01,-79.98 447.42,-70.27 454.28,-61.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"457.11,-63.31 460.39,-53.24 451.55,-59.07 457.11,-63.31\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"726.5,-157 609.5,-157 609.5,-89 726.5,-89 726.5,-157\"/>\n<text text-anchor=\"middle\" x=\"668\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[45] &lt;= 0.49</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.351</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1060</text>\n<text text-anchor=\"middle\" x=\"668\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [70, 990]</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M668,-192.88C668,-184.78 668,-175.98 668,-167.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"671.5,-167.3 668,-157.3 664.5,-167.3 671.5,-167.3\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"916.5,-157 805.5,-157 805.5,-89 916.5,-89 916.5,-157\"/>\n<text text-anchor=\"middle\" x=\"861\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">x[17] &lt;= 0.285</text>\n<text text-anchor=\"middle\" x=\"861\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.469</text>\n<text text-anchor=\"middle\" x=\"861\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\n<text text-anchor=\"middle\" x=\"861\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 7]</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M730.66,-192.88C751.75,-181.74 775.31,-169.28 796.54,-158.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"798.28,-161.11 805.48,-153.34 795.01,-154.92 798.28,-161.11\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"666.5,-53 549.5,-53 549.5,0 666.5,0 666.5,-53\"/>\n<text text-anchor=\"middle\" x=\"608\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.297</text>\n<text text-anchor=\"middle\" x=\"608\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1045</text>\n<text text-anchor=\"middle\" x=\"608\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 990]</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M647.01,-88.95C641.44,-80.17 635.41,-70.66 629.79,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"632.66,-59.8 624.34,-53.24 626.75,-63.55 632.66,-59.8\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"787,-53 685,-53 685,0 787,0 787,-53\"/>\n<text text-anchor=\"middle\" x=\"736\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"736\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"middle\" x=\"736\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 0]</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M691.78,-88.95C698.17,-80.07 705.08,-70.46 711.51,-61.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"714.48,-63.4 717.48,-53.24 708.8,-59.31 714.48,-63.4\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"916.5,-53 805.5,-53 805.5,0 916.5,0 916.5,-53\"/>\n<text text-anchor=\"middle\" x=\"861\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.116</text>\n<text text-anchor=\"middle\" x=\"861\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 64</text>\n<text text-anchor=\"middle\" x=\"861\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 1]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M861,-88.95C861,-80.72 861,-71.85 861,-63.48\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"864.5,-63.24 861,-53.24 857.5,-63.24 864.5,-63.24\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1031,-53 935,-53 935,0 1031,0 1031,-53\"/>\n<text text-anchor=\"middle\" x=\"983\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"983\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"middle\" x=\"983\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M903.67,-88.95C915.95,-79.43 929.33,-69.07 941.54,-59.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"944.01,-62.13 949.77,-53.24 939.72,-56.59 944.01,-62.13\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7ea131e23be0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the entropy varies as you go down the tree."
      ],
      "metadata": {
        "id": "lOGSLGfV6Q5e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC7tzjbZ14H-"
      },
      "source": [
        "We can use the [export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz) to customize several aspects of the tree. For example, if you look at the .pdf file generated, the names of the features are assigned by default by refering to the column index in `X`. It is possible to assign the names of the features directly. Likewise for the labels `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "arxQxLCw14H_"
      },
      "outputs": [],
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                      feature_names=spam_names[0:57],\n",
        "                      class_names=['ham', 'spam'],\n",
        "                      filled=True, rounded=True,\n",
        "                      special_characters=True)\n",
        "graph = graphviz.Source(dot_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C19mq2W914IB",
        "outputId": "5849b2e3-86b3-4492-c274-92a8d3e0b90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1040pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 1039.50 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 1035.5,-429 1035.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f6d3ba\" stroke=\"black\" d=\"M589,-425C589,-425 473,-425 473,-425 467,-425 461,-419 461,-413 461,-413 461,-354 461,-354 461,-348 467,-342 473,-342 473,-342 589,-342 589,-342 595,-342 601,-348 601,-354 601,-354 601,-413 601,-413 601,-419 595,-425 589,-425\"/>\n<text text-anchor=\"start\" x=\"470.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">char_freq_$ ≤ 0.056</text>\n<text text-anchor=\"start\" x=\"483.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.967</text>\n<text text-anchor=\"start\" x=\"482.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4601</text>\n<text text-anchor=\"start\" x=\"469\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2788, 1813]</text>\n<text text-anchor=\"start\" x=\"494\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eda876\" stroke=\"black\" d=\"M520.5,-306C520.5,-306 365.5,-306 365.5,-306 359.5,-306 353.5,-300 353.5,-294 353.5,-294 353.5,-235 353.5,-235 353.5,-229 359.5,-223 365.5,-223 365.5,-223 520.5,-223 520.5,-223 526.5,-223 532.5,-229 532.5,-235 532.5,-235 532.5,-294 532.5,-294 532.5,-300 526.5,-306 520.5,-306\"/>\n<text text-anchor=\"start\" x=\"361.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">word_freq_remove ≤ 0.055</text>\n<text text-anchor=\"start\" x=\"395.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.787</text>\n<text text-anchor=\"start\" x=\"394.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3471</text>\n<text text-anchor=\"start\" x=\"385\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2655, 816]</text>\n<text text-anchor=\"start\" x=\"406\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M500.47,-341.91C493.71,-332.92 486.48,-323.32 479.52,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"482.29,-311.91 473.48,-306.02 476.69,-316.12 482.29,-311.91\"/>\n<text text-anchor=\"middle\" x=\"469.98\" y=\"-327.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#53aae8\" stroke=\"black\" d=\"M698.5,-306C698.5,-306 589.5,-306 589.5,-306 583.5,-306 577.5,-300 577.5,-294 577.5,-294 577.5,-235 577.5,-235 577.5,-229 583.5,-223 589.5,-223 589.5,-223 698.5,-223 698.5,-223 704.5,-223 710.5,-229 710.5,-235 710.5,-235 710.5,-294 710.5,-294 710.5,-300 704.5,-306 698.5,-306\"/>\n<text text-anchor=\"start\" x=\"585.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">word_freq_hp ≤ 0.4</text>\n<text text-anchor=\"start\" x=\"596.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.523</text>\n<text text-anchor=\"start\" x=\"595.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1130</text>\n<text text-anchor=\"start\" x=\"589.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [133, 997]</text>\n<text text-anchor=\"start\" x=\"603.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M570.2,-341.91C579.06,-332.74 588.54,-322.93 597.65,-313.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"600.43,-315.65 604.86,-306.02 595.4,-310.78 600.43,-315.65\"/>\n<text text-anchor=\"middle\" x=\"605.3\" y=\"-327.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ea9a60\" stroke=\"black\" d=\"M268,-187C268,-187 158,-187 158,-187 152,-187 146,-181 146,-175 146,-175 146,-116 146,-116 146,-110 152,-104 158,-104 158,-104 268,-104 268,-104 274,-104 280,-110 280,-116 280,-116 280,-175 280,-175 280,-181 274,-187 268,-187\"/>\n<text text-anchor=\"start\" x=\"154\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">char_freq_! ≤ 0.191</text>\n<text text-anchor=\"start\" x=\"165.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.644</text>\n<text text-anchor=\"start\" x=\"164.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3141</text>\n<text text-anchor=\"start\" x=\"155\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2625, 516]</text>\n<text text-anchor=\"start\" x=\"176\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M363.2,-222.91C339.16,-210.68 312.84,-197.29 289.05,-185.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"290.56,-182.03 280.06,-180.61 287.39,-188.27 290.56,-182.03\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#4da7e8\" stroke=\"black\" d=\"M514.5,-187C514.5,-187 371.5,-187 371.5,-187 365.5,-187 359.5,-181 359.5,-175 359.5,-175 359.5,-116 359.5,-116 359.5,-110 365.5,-104 371.5,-104 371.5,-104 514.5,-104 514.5,-104 520.5,-104 526.5,-110 526.5,-116 526.5,-116 526.5,-175 526.5,-175 526.5,-181 520.5,-187 514.5,-187\"/>\n<text text-anchor=\"start\" x=\"367.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">word_freq_george ≤ 0.14</text>\n<text text-anchor=\"start\" x=\"395.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.439</text>\n<text text-anchor=\"start\" x=\"398\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 330</text>\n<text text-anchor=\"start\" x=\"392.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 300]</text>\n<text text-anchor=\"start\" x=\"402.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M443,-222.91C443,-214.65 443,-205.86 443,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"446.5,-197.02 443,-187.02 439.5,-197.02 446.5,-197.02\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M120,-68C120,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 120,0 120,0 126,0 132,-6 132,-12 132,-12 132,-56 132,-56 132,-62 126,-68 120,-68\"/>\n<text text-anchor=\"start\" x=\"18.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.412</text>\n<text text-anchor=\"start\" x=\"17.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2524</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2315, 209]</text>\n<text text-anchor=\"start\" x=\"29\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M158.26,-103.73C145.41,-94.15 131.73,-83.96 118.95,-74.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"120.81,-71.47 110.7,-68.3 116.63,-77.08 120.81,-71.47\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#fffefd\" stroke=\"black\" d=\"M263.5,-68C263.5,-68 162.5,-68 162.5,-68 156.5,-68 150.5,-62 150.5,-56 150.5,-56 150.5,-12 150.5,-12 150.5,-6 156.5,0 162.5,0 162.5,0 263.5,0 263.5,0 269.5,0 275.5,-6 275.5,-12 275.5,-12 275.5,-56 275.5,-56 275.5,-62 269.5,-68 263.5,-68\"/>\n<text text-anchor=\"start\" x=\"173\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"168\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 617</text>\n<text text-anchor=\"start\" x=\"158.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [310, 307]</text>\n<text text-anchor=\"start\" x=\"176\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M213,-103.73C213,-95.52 213,-86.86 213,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.5,-78.3 213,-68.3 209.5,-78.3 216.5,-78.3\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#44a3e6\" stroke=\"black\" d=\"M398.5,-68C398.5,-68 305.5,-68 305.5,-68 299.5,-68 293.5,-62 293.5,-56 293.5,-56 293.5,-12 293.5,-12 293.5,-6 299.5,0 305.5,0 305.5,0 398.5,0 398.5,0 404.5,0 410.5,-6 410.5,-12 410.5,-12 410.5,-56 410.5,-56 410.5,-62 404.5,-68 398.5,-68\"/>\n<text text-anchor=\"start\" x=\"304.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.302</text>\n<text text-anchor=\"start\" x=\"307\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 317</text>\n<text text-anchor=\"start\" x=\"301.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 300]</text>\n<text text-anchor=\"start\" x=\"311.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.11,-103.73C401.61,-94.7 393.66,-85.12 386.14,-76.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"388.76,-73.75 379.67,-68.3 383.37,-78.23 388.76,-73.75\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M519,-68C519,-68 441,-68 441,-68 435,-68 429,-62 429,-56 429,-56 429,-12 429,-12 429,-6 435,0 441,0 441,0 519,0 519,0 525,0 531,-6 531,-12 531,-12 531,-56 531,-56 531,-62 525,-68 519,-68\"/>\n<text text-anchor=\"start\" x=\"440\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"439\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"437\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 0]</text>\n<text text-anchor=\"start\" x=\"443\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M456.78,-103.73C459.61,-95.34 462.61,-86.47 465.47,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"468.86,-78.89 468.75,-68.3 462.23,-76.65 468.86,-78.89\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#47a4e7\" stroke=\"black\" d=\"M706,-187C706,-187 582,-187 582,-187 576,-187 570,-181 570,-175 570,-175 570,-116 570,-116 570,-110 576,-104 582,-104 582,-104 706,-104 706,-104 712,-104 718,-110 718,-116 718,-116 718,-175 718,-175 718,-181 712,-187 706,-187\"/>\n<text text-anchor=\"start\" x=\"578\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">word_freq_edu ≤ 0.49</text>\n<text text-anchor=\"start\" x=\"596.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.351</text>\n<text text-anchor=\"start\" x=\"595.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1060</text>\n<text text-anchor=\"start\" x=\"593.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [70, 990]</text>\n<text text-anchor=\"start\" x=\"603.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M644,-222.91C644,-214.65 644,-205.86 644,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"647.5,-197.02 644,-187.02 640.5,-197.02 647.5,-197.02\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M932,-187C932,-187 790,-187 790,-187 784,-187 778,-181 778,-175 778,-175 778,-116 778,-116 778,-110 784,-104 790,-104 790,-104 932,-104 932,-104 938,-104 944,-110 944,-116 944,-116 944,-175 944,-175 944,-181 938,-187 932,-187\"/>\n<text text-anchor=\"start\" x=\"786\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">word_freq_email ≤ 0.285</text>\n<text text-anchor=\"start\" x=\"813.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.469</text>\n<text text-anchor=\"start\" x=\"820\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 70</text>\n<text text-anchor=\"start\" x=\"818\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 7]</text>\n<text text-anchor=\"start\" x=\"824\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M710.58,-227.6C731.5,-216.32 754.87,-203.72 776.83,-191.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"778.68,-194.86 785.82,-187.03 775.36,-188.7 778.68,-194.86\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#44a2e6\" stroke=\"black\" d=\"M654.5,-68C654.5,-68 561.5,-68 561.5,-68 555.5,-68 549.5,-62 549.5,-56 549.5,-56 549.5,-12 549.5,-12 549.5,-6 555.5,0 561.5,0 561.5,0 654.5,0 654.5,0 660.5,0 666.5,-6 666.5,-12 666.5,-12 666.5,-56 666.5,-56 666.5,-62 660.5,-68 654.5,-68\"/>\n<text text-anchor=\"start\" x=\"560.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.297</text>\n<text text-anchor=\"start\" x=\"559.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1045</text>\n<text text-anchor=\"start\" x=\"557.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 990]</text>\n<text text-anchor=\"start\" x=\"567.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M630.59,-103.73C627.84,-95.34 624.92,-86.47 622.14,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"625.4,-76.71 618.95,-68.3 618.75,-78.89 625.4,-76.71\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M775,-68C775,-68 697,-68 697,-68 691,-68 685,-62 685,-56 685,-56 685,-12 685,-12 685,-6 691,0 697,0 697,0 775,0 775,0 781,0 787,-6 787,-12 787,-12 787,-56 787,-56 787,-62 781,-68 775,-68\"/>\n<text text-anchor=\"start\" x=\"696\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"695\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"693\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 0]</text>\n<text text-anchor=\"start\" x=\"699\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M678.26,-103.73C685.84,-94.7 693.89,-85.12 701.48,-76.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"704.27,-78.21 708.02,-68.3 698.91,-73.7 704.27,-78.21\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#e5833c\" stroke=\"black\" d=\"M904.5,-68C904.5,-68 817.5,-68 817.5,-68 811.5,-68 805.5,-62 805.5,-56 805.5,-56 805.5,-12 805.5,-12 805.5,-6 811.5,0 817.5,0 817.5,0 904.5,0 904.5,0 910.5,0 916.5,-6 916.5,-12 916.5,-12 916.5,-56 916.5,-56 916.5,-62 910.5,-68 904.5,-68\"/>\n<text text-anchor=\"start\" x=\"813.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.116</text>\n<text text-anchor=\"start\" x=\"820\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 64</text>\n<text text-anchor=\"start\" x=\"818\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 1]</text>\n<text text-anchor=\"start\" x=\"824\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = ham</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M861,-103.73C861,-95.52 861,-86.86 861,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"864.5,-78.3 861,-68.3 857.5,-78.3 864.5,-78.3\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1019.5,-68C1019.5,-68 946.5,-68 946.5,-68 940.5,-68 934.5,-62 934.5,-56 934.5,-56 934.5,-12 934.5,-12 934.5,-6 940.5,0 946.5,0 946.5,0 1019.5,0 1019.5,0 1025.5,0 1031.5,-6 1031.5,-12 1031.5,-12 1031.5,-56 1031.5,-56 1031.5,-62 1025.5,-68 1019.5,-68\"/>\n<text text-anchor=\"start\" x=\"943\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"945.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"943.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n<text text-anchor=\"start\" x=\"942.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = spam</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M906.43,-103.73C916.9,-94.33 928.02,-84.35 938.45,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"940.79,-77.58 945.9,-68.3 936.12,-72.37 940.79,-77.58\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7ea0fb31b3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCYJpLsr14IC"
      },
      "source": [
        "One could quickly use the tree generated for the purposes of [feature selection](https://en.wikipedia.org/wiki/Feature_selection). Feature selection is a whole research area in machine learning with a very practical purpose: being able to identify which features are more relevant in a prediction problem. In modern big data applications, the amount of features generated is huge. For example, one could extract thousands of millions of features from a genome sequence that maps to a particular medical disorder. Finding which features are more relevant for correctly classifying the disorder could lead to breakthroughs in medicine.\n",
        "\n",
        "Relevant features can be identified starting from the top level of the tree and going down to the leaf nodes. For example, one can argue that the most important feature is the one used in the root node (e.g. char_freq_$ for the Spambase dataset) since it has the highest entropy.    \n",
        "\n",
        "## Evaluating the prediction ability of a decision tree classifier\n",
        "\n",
        "We will now evaluate the predictive ability of the decision tree classifier on a subset of the Spam dataset. The Decision Tree has several tunable parameters, including, the criterion or impurity measure (criterion) and the maximum depth of the tree (max_depth). A complete list of parameters for the DecisionTreeClassifier implemented in scikit-learn can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).\n",
        "\n",
        "We will create a simple Grid Search for finding the best parameters for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wSgn5ak014IE"
      },
      "outputs": [],
      "source": [
        "# We first split the data into a train and a test set.\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "ss = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "indexes = list(ss.split(X, y))\n",
        "train_set  = indexes[0][0]\n",
        "test_set  = indexes[0][1]\n",
        "Xtrain = X.iloc[train_set, :]\n",
        "ytrain = y.iloc[train_set]\n",
        "Xtest = X.iloc[test_set, :]\n",
        "ytest = y.iloc[test_set]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxt5dsKO14IH"
      },
      "source": [
        "We now create a Grid search for the parameters criterion and max_depth and we use the training data to find the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c8X_TpQn14II",
        "outputId": "82e9455f-2692-4426-a308-835859f01d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.3, train_size=None),\n",
              "             estimator=DecisionTreeClassifier(),\n",
              "             param_grid={'criterion': array(['entropy', 'gini'], dtype='<U7'),\n",
              "                         'max_depth': [3, 5, 10, 15]},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.3, train_size=None),\n",
              "             estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: array([&#x27;entropy&#x27;, &#x27;gini&#x27;], dtype=&#x27;&lt;U7&#x27;),\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 10, 15]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.3, train_size=None),\n",
              "             estimator=DecisionTreeClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: array([&#x27;entropy&#x27;, &#x27;gini&#x27;], dtype=&#x27;&lt;U7&#x27;),\n",
              "                         &#x27;max_depth&#x27;: [3, 5, 10, 15]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV # For model selection\n",
        "criterion_opts = np.array(['entropy', 'gini'])\n",
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid = dict(criterion = criterion_opts, max_depth = max_depth_opts)\n",
        "cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "grid = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, cv=cv, scoring='accuracy')\n",
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKg7DeCI14IJ"
      },
      "source": [
        "We can see now which ones were the best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6_LEkIG914IK",
        "outputId": "3ec29407-5342-43f4-d2cc-c5bb4005fd68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKS2s4uy14IM"
      },
      "source": [
        "We then train a new decision tree using those parameters and then evaluate the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QUKJG5_314IN"
      },
      "outputs": [],
      "source": [
        "clf = tree.DecisionTreeClassifier(criterion=grid.best_params_[\"criterion\"],max_depth=grid.best_params_[\"max_depth\"])\n",
        "clf.fit(Xtrain, ytrain)\n",
        "ypred = clf.predict(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gpZZeXz14IO"
      },
      "source": [
        "We now evaluate the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hZ7iDysh14IP",
        "outputId": "e56e741c-bc66-41dc-fdd3-85fddd4980ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9138305575669804\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score # Accuracy score\n",
        "accuracy = accuracy_score(ytest, ypred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiRy_fcU14IQ"
      },
      "source": [
        "### Distribution of the labels\n",
        "\n",
        "Let us look at the distribution of the instances for class in the original dataset and in the training data.\n",
        "\n",
        ">**Warning for MAC OS users** As of today, the current installation of `graphviz` **may** put its own version of freetype into the default python runtime library path. However, matplotlib needs a different version of the same library. The fix is explained in [this entry of stackoverflow](https://stackoverflow.com/questions/28028786/matplotlib-error-libfreetype-6-dylib)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hnJiF2rn14IR",
        "outputId": "da71befe-1eca-41cc-f981-c80e7cfc8e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "y.hist()\n",
        "plt.ylabel('Number of instances')\n",
        "plt.xlabel('Class label')\n",
        "plt.title('Class distribution for X')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AIP3TjC14IT"
      },
      "source": [
        "Notice that the numbers of data observations per class are different. We usually refer to this kind of problems as \"imbalanced\".\n",
        "\n",
        "Bear in mind that when creating your training data, you need to account for this imbalance and be aware against misleading results. For example, accuracy is probably not a good metric to measure performance in these problems:\n",
        "\n",
        "> If you have 99% of your data in one class, and 1% in a second class. A simple classifier (that reports the first class for all test points) will get about 99% accuracy. Many classifiers might end up just reporting the majority class.\n",
        "\n",
        "There are different [strategies for balancing a dataset](https://books.google.co.uk/books/about/Imbalanced_Learning.html?id=YqQJngEACAAJ&redir_esc=y) but if for some reason you are not able to balance it, it is important to be aware of these issues. Some stategies include: i) under-sampling the majority class(es), ii) over-sampling the minority class, and iii) combining over- and under-sampling. The python package [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn#id22) has several implementations of these different strategies. You can install the package and try some of them.\n",
        "\n",
        "### Question 1\n",
        "\n",
        "A simple strategy we can use to balance the problem for the Spam dataset is to under-sample the majority class. Repeat the spam prediction problem above but make sure you have the same number of samples in both classses.\n",
        "Do you notice any difference in the accuracy over the same test set that we used before? Also, use a performance measure that takes into account imbalanced data. Do you see any difference between this new performance measure before and after balancing the classes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lvR6jaU314IU",
        "outputId": "8a936999-ddbf-4797-d4f6-d7bade71a27a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Provide your answer here\n",
        "# under_sample the majoruty class ,\n",
        "\n",
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy= 0.7)\n",
        "X_resampled, y_resampled = rus.fit_resample(Xtrain, ytrain)\n",
        "\n",
        "# split the data\n",
        "X_retrain, X_reval, y_retrain, y_reval =train_test_split(X_resampled, y_resampled, test_size =0.25)\n",
        "\n",
        "#train a machine learning model\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_reval = clf.predict(X_reval)\n",
        "accuracy = np.sum(y_pred_reval == y_reval) / len(y_reval)\n",
        "print ('Accuracy on validation set:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the predi\n",
        "\n",
        "\n",
        "#we've not looked much at the problem of assessing quality of a classifier in imbalanced data...\n",
        "# quick note, ROC (area under the curve) can be good - but also can be affected by imbalanced data. Precision-recall curves can help.\n",
        "# also consider f1-score."
      ],
      "metadata": {
        "id": "gfbybjVnSO0k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4teLE0OSOlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2NUTaTw14IU"
      },
      "source": [
        "## Decision trees for regression\n",
        "\n",
        "The main difference between Decision Tress for Classification and Decision Trees for Regression is in the impurity measure used. The [decision trees for regression implemented in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) uses the mean squared error by default as the impurity measure. The mean squared error is closely related with the variance, the impurity measure we introduced in the Session for this week.\n",
        "\n",
        "We are going to go back to the dataset of Bike rentals that we used in Lab 2 and compare the performance of the decision tree for regression over the same partitions of train, validation and test sets that we used back there for the linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FEzwORSM14IW"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv', './SeoulBikeData.csv')\n",
        "bike_sharing_data = pd.read_csv('SeoulBikeData.csv', encoding= 'unicode_escape')\n",
        "bike_sharing_data = bike_sharing_data.drop('Date', axis=1)\n",
        "# We transform the int64 variables in the dataset to float64.\n",
        "for col in ['Rented Bike Count', 'Hour', 'Humidity(%)', 'Visibility (10m)']:\n",
        "    bike_sharing_data[col] = bike_sharing_data[col].astype('float64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpoZUhmd14IW"
      },
      "source": [
        "We split the data into train and test sets. Have a look at the random_state. We use the same number from Lab 2 to make sure the splits into train and test are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "cTT14uJb14IZ",
        "outputId": "865508f0-ae44-4fe2-8985-50047a4b62eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
            "5852             1441.0  20.0             34.5         62.0               2.8   \n",
            "7568             1996.0   8.0              6.0         64.0               1.1   \n",
            "5970             1956.0  18.0             32.8         63.0               1.3   \n",
            "6791              941.0  23.0             21.2         56.0               2.5   \n",
            "576               160.0   0.0             -0.6         64.0               2.4   \n",
            "...                 ...   ...              ...          ...               ...   \n",
            "5734             1507.0  22.0             29.9         74.0               2.0   \n",
            "5191              828.0   7.0             23.5         90.0               0.5   \n",
            "5390              999.0  14.0             29.5         62.0               2.7   \n",
            "860               322.0  20.0             -3.4         51.0               1.1   \n",
            "7270             1501.0  22.0             19.3         55.0               0.5   \n",
            "\n",
            "      Visibility (10m)  Dew point temperature(°C)  Solar Radiation (MJ/m2)  \\\n",
            "5852            1701.0                       26.1                     0.02   \n",
            "7568            1920.0                       -0.3                     0.42   \n",
            "5970            1799.0                       24.8                     0.31   \n",
            "6791            2000.0                       12.0                     0.00   \n",
            "576             1010.0                       -6.5                     0.00   \n",
            "...                ...                        ...                      ...   \n",
            "5734            1201.0                       24.7                     0.00   \n",
            "5191             445.0                       21.7                     0.05   \n",
            "5390            1941.0                       21.4                     1.79   \n",
            "860             1391.0                      -12.1                     0.00   \n",
            "7270            2000.0                       10.0                     0.00   \n",
            "\n",
            "      Rainfall(mm)  Snowfall (cm) Seasons     Holiday Functioning Day  \n",
            "5852           0.0            0.0  Summer  No Holiday             Yes  \n",
            "7568           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "5970           0.0            0.0  Summer  No Holiday             Yes  \n",
            "6791           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "576            0.0            0.0  Winter     Holiday             Yes  \n",
            "...            ...            ...     ...         ...             ...  \n",
            "5734           0.0            0.0  Summer  No Holiday             Yes  \n",
            "5191           0.5            0.0  Summer  No Holiday             Yes  \n",
            "5390           0.0            0.0  Summer  No Holiday             Yes  \n",
            "860            0.0            0.0  Winter  No Holiday             Yes  \n",
            "7270           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "\n",
            "[7446 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "bs_train_set, bs_test_set = train_test_split(bike_sharing_data, test_size=0.15, random_state=42)\n",
        "print(bs_train_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVvXS-TY14If"
      },
      "source": [
        "We perform the same data preprocessing step for the input features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NzMcUwLR14Ig"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "attributes_cat = ['Seasons', 'Holiday', 'Functioning Day']\n",
        "attributes_num = ['Hour', 'Temperature(°C)', 'Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)', \\\n",
        "                  'Dew point temperature(°C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']\n",
        "\n",
        "\n",
        "# 这里的num 指的是与数据相关的数据，而cat则是一些可以用分类表达的内容，比如week, season , holiday\n",
        "full_transform = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), attributes_num),\n",
        "    (\"cat\", OneHotEncoder(), attributes_cat),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uwlR85K14Ih"
      },
      "source": [
        "We further create a train and a validation set from the original train set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs_train2_set, bs_val_set = train_test_split(bs_train_set, test_size=0.15, random_state=42)\n",
        "bs_train2_set_attributes = bs_train2_set.drop('Rented Bike Count', axis=1)\n",
        "bs_train2_set_labels = bs_train2_set['Rented Bike Count']\n",
        "bs_val_set_attributes = bs_val_set.drop('Rented Bike Count', axis=1)\n",
        "bs_val_set_labels = bs_val_set['Rented Bike Count']"
      ],
      "metadata": {
        "id": "_wJFt8C2loM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGbtVzoK14Ii"
      },
      "source": [
        "We fit transform the attributes in the train set and transform them in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jeo4KMSu14Ij"
      },
      "outputs": [],
      "source": [
        "# fit transform in the train set\n",
        "bs_train2_set_attributes_transformed = full_transform.fit_transform(bs_train2_set_attributes)\n",
        "# transform in the validation set\n",
        "bs_val_set_attributes_transformed = full_transform.transform(bs_val_set_attributes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnXU9kSU14Ik"
      },
      "source": [
        "Since we want to perform a GridSearchCV on the same validation data that we used for Lab 2, we will use [`PredefinedSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit) to tell the cross validator which instances to use for training and which ones for validation. We create first a test_fold array of the same dimensionality than the original training data and assign the value of -1 to the indexes corresponding to train instances and 0 to the indexes corresponding to validation instances. We will then stack the input attributes for both sets and also stack the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FC6mAsxX14Ik"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "test_fold = np.zeros((np.shape(bs_train_set)[0], 1))\n",
        "test_fold[0:np.shape(bs_train2_set)[0]] = -1\n",
        "ps = PredefinedSplit(test_fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68PPGqNO14Il"
      },
      "source": [
        "We concatenate the attributes and the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dzAO6Hps14Il"
      },
      "outputs": [],
      "source": [
        "whole_train_set_attributes = np.vstack((bs_train2_set_attributes_transformed , bs_val_set_attributes_transformed))\n",
        "whole_train_set_labels = np.hstack((bs_train2_set_labels, bs_val_set_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYl7Mp6C14Il"
      },
      "source": [
        "We can now apply the decision tree for regression and explore different maximum depth options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ungm6AB114In",
        "outputId": "09179d37-33b3-48fd-caea-9820e988693d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=DecisionTreeRegressor(),\n",
              "             param_grid={'max_depth': [3, 5, 10, 15]},\n",
              "             scoring='neg_mean_squared_error')"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [3, 5, 10, 15]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             estimator=DecisionTreeRegressor(),\n",
              "             param_grid={&#x27;max_depth&#x27;: [3, 5, 10, 15]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid = dict(max_depth = max_depth_opts)\n",
        "grid_regression = GridSearchCV(tree.DecisionTreeRegressor(), param_grid=param_grid, cv=ps, scoring='neg_mean_squared_error')\n",
        "grid_regression.fit(whole_train_set_attributes, whole_train_set_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAEU6YLx14In"
      },
      "source": [
        "Let us train now a decision tree regressor using the best value for the max depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "LAucOPDE14It"
      },
      "outputs": [],
      "source": [
        "regr = tree.DecisionTreeRegressor(max_depth=grid_regression.best_params_[\"max_depth\"], random_state=42)\n",
        "regr.fit(bs_train2_set_attributes_transformed, bs_train2_set_labels)\n",
        "bs_val_set_predictions = regr.predict(bs_val_set_attributes_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3GyVMQ814Iu"
      },
      "source": [
        "And now we compute the RMSE for the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "asCeDeNm14Iu",
        "outputId": "c8a73d82-b69d-4d46-85f4-2d8b6ff07bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "271.71631148738953"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "error_mod = np.sqrt(mean_squared_error(bs_val_set_labels, bs_val_set_predictions))\n",
        "error_mod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKvbmWdK14Ix"
      },
      "source": [
        "We notice how this is a great improvement compared to the result obtained using linear regression in Lab Notebook 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbMLD5kT14Ix"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Decision trees do not require any scaling of the features. Use the same splits of the data than before but use the numerical features as they come, this is, do not use StandardScaler() for the numerical features. What is the RMSE on the validation data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "byUU7LZR14Iy"
      },
      "outputs": [],
      "source": [
        "# Provide your answer here\n",
        "bs_train3_set, bs_val3_set = train_test_split(bs_train_set, test_size=0.15, random_state=42)\n",
        "bs_train3_set_attributes = bs_train3_set.drop('Rented Bike Count', axis=1)\n",
        "bs_train3_set_labels = bs_train3_set['Rented Bike Count']\n",
        "bs_val3_set_attributes = bs_val3_set.drop('Rented Bike Count', axis=1)\n",
        "bs_val3_set_labels = bs_val3_set['Rented Bike Count']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # fit transform in the train set\n",
        "# bs_train2_set_attributes_transformed = full_transform.fit_transform(bs_train2_set_attributes)\n",
        "# # transform in the validation set\n",
        "# bs_val_set_attributes_transformed = full_transform.transform(bs_val_set_attributes)"
      ],
      "metadata": {
        "id": "xNbxH03GqITV"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "test_fold = np.zeros((np.shape(bs_train_set)[0], 1))\n",
        "test_fold[0:np.shape(bs_train3_set)[0]] = -1\n",
        "ps = PredefinedSplit(test_fold)"
      ],
      "metadata": {
        "id": "YRQPrpPql4cu"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whole_train_set_attributes = np.vstack((bs_train3_set_attributes , bs_val3_set_attributes))\n",
        "whole_train_set_labels = np.hstack((bs_train3_set_labels, bs_val3_set_labels))"
      ],
      "metadata": {
        "id": "GNhx7aG0pwg7"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid = dict(max_depth = max_depth_opts)\n",
        "grid_regression = GridSearchCV(tree.DecisionTreeRegressor(), param_grid=param_grid, cv=ps, scoring='neg_mean_squared_error')\n",
        "grid_regression.fit(whole_train_set_attributes, whole_train_set_labels)"
      ],
      "metadata": {
        "id": "4BFsYzSWpz2r",
        "outputId": "7e7f5549-31fc-4779-ba2b-12feda51c7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-b9bc3ea76d06>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole_train_set_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhole_train_set_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 4 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n    super().fit(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 186, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 579, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_X_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'Summer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regr = tree.DecisionTreeRegressor(max_depth=grid_regression.best_params_[\"max_depth\"], random_state=42)\n",
        "regr.fit(bs_train2_set_attributes_transformed, bs_train2_set_labels)\n",
        "bs_val_set_predictions = regr.predict(bs_val_set_attributes_transformed)"
      ],
      "metadata": {
        "id": "K5W4jbDtp3XT",
        "outputId": "21e75ccf-8e79-4066-e4de-bc49bd064c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-b0feef26a735>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_train2_set_attributes_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs_train2_set_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbs_val_set_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_val_set_attributes_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "error_mod = np.sqrt(mean_squared_error(bs_val_set_labels, bs_val_set_predictions))\n",
        "error_mod"
      ],
      "metadata": {
        "id": "atgG_SXKp7Ll",
        "outputId": "5a9794da-44c2-4baf-d55f-9ced47fbbf26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "271.71631148738953"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2G1OZ3514Iy"
      },
      "source": [
        "## Ensemble learning\n",
        "\n",
        "In machine learning, we use the term ensemble model to refer to a predictive model that is a composition of several other predictive models. For example, for a classification problem, we can have an ensemble of three classifiers, where the first of them is a decision tree classifier, the second one is a logistic regressor (to be studied in Session 6) and the third one is a shallow neural network. We can train all classifiers with the same training data and then, at test time, predictions can be done using majority voting.\n",
        "\n",
        "Ensemble methods are very popular since they usually show higher performance when compared to simpler classifiers. In fact, gradient boosting trees are the most popular method in [**Kaggle**](https://www.kaggle.com/), a platform that hosts data science competitions. The top entry in the [**Netflix Prize**](https://en.wikipedia.org/wiki/Netflix_Prize) Competition, one of the most famous data science competitions, was based on an ensemble predictive model.\n",
        "\n",
        "The most commmon ensemble methods use decision trees as the members of the ensemble. Scikit-learn implemenst two types of Tree Ensembles, random forests and gradient boosting. The main difference between both methods is the way in which they combine the different trees that compose the ensemble.\n",
        "\n",
        "### Random Forests\n",
        "\n",
        "The tree ensemble in random forests is built by training individual decision trees on different subsets of the training data and using a subset of the available features. For classification, the prediction is done by majority voting among the individual trees. In fact, according to Scikit-learn documentation for the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) \"The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.\" For regression, the prediction is the average of the individual predictions of each tree.\n",
        "\n",
        "Some of the additional parameters required in the Random Forest implementation in Scikit-learn include\n",
        "\n",
        "> **n_estimators** the total number of trees to train<p>\n",
        "**max_features** number of features to use as candidates for splitting at each tree node. <p>\n",
        "    **boostrap**: Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.<p>\n",
        "   **max_samples**: If bootstrap is True, the number of samples to draw from X to train each base estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSCYbF9w14Iz"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Train a [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) on the Bike rentals dataset and evaluate the performance on the same data set partition that we had before. Create a grid search to test different values for the parameters **n_estimators** and **max_samples**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "bs_train_set, bs_test_set = train_test_split(bike_sharing_data, test_size=0.15, random_state=42)\n",
        "print(bs_train_set)\n",
        "\n",
        "## whayt is x and what is y here?\n",
        "X = bs_train_set['Rented Bike Count']\n",
        "y\n",
        "\n",
        "# 3. create a randomforestregressor object and specify the hyperameters\n",
        "# model = RandomForestRegressor()\n",
        "# param_grid = {\n",
        "#     'n_estimators': [100, 200, 500],\n",
        "#     'max_samples': ['sqrt', 'log2', None]\n",
        "# }\n",
        "\n",
        "# #4. Create a GridSearchCV object\n",
        "# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "\n",
        "# # Fit the GridSearchCV object to the training data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Get the best model from the grid search\n",
        "# best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "JsS07zeH3AvQ",
        "outputId": "49b60040-109b-4351-d5a5-f6270db14b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  Wind speed (m/s)  \\\n",
            "5852             1441.0  20.0             34.5         62.0               2.8   \n",
            "7568             1996.0   8.0              6.0         64.0               1.1   \n",
            "5970             1956.0  18.0             32.8         63.0               1.3   \n",
            "6791              941.0  23.0             21.2         56.0               2.5   \n",
            "576               160.0   0.0             -0.6         64.0               2.4   \n",
            "...                 ...   ...              ...          ...               ...   \n",
            "5734             1507.0  22.0             29.9         74.0               2.0   \n",
            "5191              828.0   7.0             23.5         90.0               0.5   \n",
            "5390              999.0  14.0             29.5         62.0               2.7   \n",
            "860               322.0  20.0             -3.4         51.0               1.1   \n",
            "7270             1501.0  22.0             19.3         55.0               0.5   \n",
            "\n",
            "      Visibility (10m)  Dew point temperature(°C)  Solar Radiation (MJ/m2)  \\\n",
            "5852            1701.0                       26.1                     0.02   \n",
            "7568            1920.0                       -0.3                     0.42   \n",
            "5970            1799.0                       24.8                     0.31   \n",
            "6791            2000.0                       12.0                     0.00   \n",
            "576             1010.0                       -6.5                     0.00   \n",
            "...                ...                        ...                      ...   \n",
            "5734            1201.0                       24.7                     0.00   \n",
            "5191             445.0                       21.7                     0.05   \n",
            "5390            1941.0                       21.4                     1.79   \n",
            "860             1391.0                      -12.1                     0.00   \n",
            "7270            2000.0                       10.0                     0.00   \n",
            "\n",
            "      Rainfall(mm)  Snowfall (cm) Seasons     Holiday Functioning Day  \n",
            "5852           0.0            0.0  Summer  No Holiday             Yes  \n",
            "7568           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "5970           0.0            0.0  Summer  No Holiday             Yes  \n",
            "6791           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "576            0.0            0.0  Winter     Holiday             Yes  \n",
            "...            ...            ...     ...         ...             ...  \n",
            "5734           0.0            0.0  Summer  No Holiday             Yes  \n",
            "5191           0.5            0.0  Summer  No Holiday             Yes  \n",
            "5390           0.0            0.0  Summer  No Holiday             Yes  \n",
            "860            0.0            0.0  Winter  No Holiday             Yes  \n",
            "7270           0.0            0.0  Autumn  No Holiday             Yes  \n",
            "\n",
            "[7446 rows x 13 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-22bdf6d1e8e3>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Fit the GridSearchCV object to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Get the best model from the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             )\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array 254.0 cannot be considered a valid collection."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKgFPuHN14I2"
      },
      "source": [
        "### Gradient Boosting\n",
        "\n",
        "In [Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting) or [Gradient-boosted trees](https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting) (GBT), each tree in the ensemble is trained sequentially: the first tree is trained as usual using the training data, the second tree is trained on the residuals between the predictions of the first tree and the labels of the training data, the third tree is trained on the residuals of the predictions of the second tree, etc. The predictions of the ensemble will be the sum of the predictions of each individual tree. The type of residuals are related to the loss function that wants to be minimised.   \n",
        "\n",
        "Scikit-learn uses the classes [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html?highlight=gradient%20boosting#sklearn.ensemble.GradientBoostingRegressor) for the implementation of Gradient-Boosted trees for regression and [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html?highlight=gradient%20boosting#sklearn.ensemble.GradientBoostingClassifier) for the implementation of Gradient-Boosted trees for binary classification.\n",
        "\n",
        "Besides the parameters that can be specified for Decision Trees, both classes share some of the additional following parameters\n",
        "\n",
        "> **n_estimators** the number of boosting stages to perform.<p>\n",
        "  **subsample** the fraction of samples to be used for fitting the individual base learners.<p>\n",
        "  **max_features** The number of features to consider when looking for the best split:    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "XOIHFIHj14I1",
        "outputId": "45d19067-1e11-4479-fa79-c4820ea4309f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5852    1441.0\n",
            "7568    1996.0\n",
            "5970    1956.0\n",
            "6791     941.0\n",
            "576      160.0\n",
            "         ...  \n",
            "5734    1507.0\n",
            "5191     828.0\n",
            "5390     999.0\n",
            "860      322.0\n",
            "7270    1501.0\n",
            "Name: Rented Bike Count, Length: 7446, dtype: float64\n",
            "y: 254.0\n"
          ]
        }
      ],
      "source": [
        "# Provide your answer here\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "X_train = bs_train_set['Rented Bike Count']\n",
        "y_train = bs_test_set['Rented Bike Count'][0]\n",
        "\n",
        "bs_train_set, bs_test_set\n",
        "print(X_train)\n",
        "print('y:', y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnEmhnaS14I2"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Repeat Question 3 but using a [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html?highlight=gradient%20boosting#sklearn.ensemble.GradientBoostingRegressor) using parameters **n_estimators** and **max_features**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYJxAojj14I3"
      },
      "outputs": [],
      "source": [
        "# Provide your answer here"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}